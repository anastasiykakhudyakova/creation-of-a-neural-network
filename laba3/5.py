#Измените значение true_prediction на другое значение (например, 0.8 или 0.5) и запустите код снова. 
#Как изменение желаемого выходного значения влияет на обучение нейросети? 
#Объясните результаты.                       Влияет на скорость обучения т.к. влияет на величину ошибки.

# Импортируем библиотеку numpy для математических операций
import numpy as np

# Функция нейронной сети: простейший перцептрон с одним нейроном
# Принимает входное значение (inp) и вес (weight)
# Возвращает результат умножения входа на вес (линейная функция)
def neural_networks(inp, weight):
    return inp * weight

# Функция вычисления квадратичной ошибки (Mean Squared Error - MSE)
# Принимает целевое значение (true_prediction) и предсказание модели (prediction)
# Возвращает квадрат разности между целевым и предсказанным значениями
def get_error(true_prediction, prediction):
    return (true_prediction - prediction) ** 2

# Функция градиентного спуска для обучения нейронной сети
# Принимает: inp - входное значение, weight - начальный вес, 
#            true_prediction - целевое значение, которое должна предсказать сеть
# Выполняет 10 итераций обучения (цикл for i in range(10))
def gradient(inp, weight, true_prediction):
    # Цикл обучения: 10 итераций 
    for i in range(10): 
        # Вычисляем предсказание нейронной сети для текущего веса
        prediction = neural_networks(inp, weight)
        # Вычисляем ошибку между целевым значением и предсказанием
        error = get_error(true_prediction, prediction)
        # Выводим текущие значения с форматированием:
        # - Prediction с 10 знаками после запятой
        # - Weight с 5 знаками после запятой  
        # - Error с 20 знаками после запятой
        print("Prediction: %.10f, Weight: %.5f, Error: %.20f" %(prediction, weight, error))
        # Вычисляем градиент (производную ошибки по весу):
        # Формула градиента для MSE: dE/dw = 2*(prediction - true)*inp
        # В данном коде множитель 2 опущен для упрощения
        delta = (prediction - true_prediction) * inp
        # Обновляем вес по правилу градиентного спуска:
        # weight_new = weight_old - learning_rate * gradient
        # Здесь learning_rate = 1 (неявно), так как просто вычитаем delta
        weight = weight - delta

# Запуск 1: целевое значение = 0.18
# Параметры: вход = 0.9, начальный вес = 0.2, цель = 0.18
gradient(0.9, 0.2, 0.18)

# Пустая строка для разделения выводов
print()

# Запуск 2: целевое значение = 0.5  
# Параметры те же: вход = 0.9, начальный вес = 0.2, но цель = 0.5
gradient(0.9, 0.2, 0.5)
